import os
import cv2
import numpy as np
import joblib
import json
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# ==== Load ONNX model ====
from facial_fer_model import FacialExpressionRecog  # from OpenCV Zoo

onnx_path = "../facial_expression_recognition/facial_expression_recognition_mobilefacenet_2022july.onnx"
recognizer = FacialExpressionRecog(onnx_path)

# ==== Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng (7 l·ªõp softmax) ====
def extract_softmax_feature(img_path, recognizer):
    img = cv2.imread(img_path)
    if img is None:
        print("‚ùå L·ªói ƒë·ªçc ·∫£nh:", img_path)
        return None

    img = cv2.resize(img, (112, 112))
    img = img.astype(np.float32)

    result = recognizer.infer(img)

    return result  # output softmax (7 l·ªõp)

# ==== G·ªôp t·∫≠p d·ªØ li·ªáu ƒë·∫∑c tr∆∞ng (bao g·ªìm l·ªõp m·ªõi) ====
def build_dataset(images_dir, recognizer):
    X = []
    y = []
    label_names = []

    class_names = sorted([
        name for name in os.listdir(images_dir)
        if os.path.isdir(os.path.join(images_dir, name))
    ])
    label_names = class_names  # G√°n 1 l·∫ßn duy nh·∫•t

    for idx, class_name in enumerate(class_names):
        class_dir = os.path.join(images_dir, class_name)

        for fname in os.listdir(class_dir):
            if not fname.lower().endswith(('.jpg', '.png', '.jpeg', '.bmp')):
                continue
            path = os.path.join(class_dir, fname)
            feat = extract_softmax_feature(path, recognizer)
            if feat is not None:
                X.append(feat)
                y.append(idx)

    return np.array(X), np.array(y), label_names

def train_classifier(X, y):
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, stratify=y, test_size=0.2, random_state=42)

    model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')
    model.fit(X_train, y_train)

    acc = accuracy_score(y_test, model.predict(X_test))
    print(f"‚úÖ Accuracy: {acc:.4f}")
    return model

# ==== L∆∞u model v√† nh√£n ====
def save_model(model, label_names, out_dir='../../model/facial_expression_recognition'):
    os.makedirs(out_dir, exist_ok=True)
    joblib.dump(model, os.path.join(out_dir, 'svc_facial_expression_classifier.pkl'))
    with open(os.path.join(out_dir, 'facial_expression_label_names.json'), 'w') as f:
        json.dump(label_names, f)
    print("‚úÖ Model v√† nh√£n ƒë√£ ƒë∆∞·ª£c l∆∞u.")

# ==== Inference th·ª≠ ====
def predict_emotion(image_path, recognizer, classifier, label_names):
    feat = extract_softmax_feature(image_path, recognizer)
    if feat is None:
        return "Unknown"
    pred = classifier.predict([feat])[0]
    return label_names[pred]

# ==== MAIN ====
if __name__ == "__main__":
    images_dir = "images"  # Th∆∞ m·ª•c ch·ª©a c√°c th∆∞ m·ª•c con: Happy/, Sleepy/, ...
    print("üìÅ Loading dataset...")
    X, y, label_names = build_dataset(images_dir, recognizer)

    print("üéì Training classifier...")
    model = train_classifier(X, y)

    print("üíæ Saving model...")
    save_model(model, label_names)

    # Inference th·ª≠
    test_img = "sleep.jpg"  # Thay b·∫±ng ·∫£nh th·ª≠ c·ªßa b·∫°n
    if os.path.exists(test_img):
        pred = predict_emotion(test_img, recognizer, model, label_names)
        print(f"üß† D·ª± ƒëo√°n c·∫£m x√∫c cho ·∫£nh '{test_img}': {pred}")
    else:
        print("üì∏ File test kh√¥ng t·ªìn t·∫°i ‚Äî b·ªè qua inference.")

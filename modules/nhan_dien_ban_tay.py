import cv2
import streamlit as st
import mediapipe as mp
import joblib
import numpy as np
from PIL import Image, ImageDraw, ImageFont

def show():
    # Load m√¥ h√¨nh
    model = joblib.load('./model/hand_gesture_model.pkl')
    labels = model.classes_

    # T·∫°o t·ª´ ƒëi·ªÉn √°nh x·∫° nh√£n ti·∫øng Anh sang ti·∫øng Vi·ªát
    label_mapping = {
        'thumbs_down': 'Ng√≥n tay c√°i xu·ªëng',
        'thumbs_up': 'Ng√≥n tay c√°i l√™n',
        'peace': 'D·∫•u h√≤a b√¨nh',
        'rock': 'D·∫•u ƒë√°',
        'open_hand': 'B√†n tay m·ªü',
        'fist': 'N·∫Øm tay',
        'pointing': 'Ch·ªâ tay',
        # Th√™m c√°c nh√£n kh√°c t√πy theo m√¥ h√¨nh c·ªßa b·∫°n
    }

    # Kh·ªüi t·∫°o MediaPipe
    mp_hands = mp.solutions.hands
    mp_drawing = mp.solutions.drawing_utils
    hands = mp_hands.Hands(static_image_mode=False,
                        max_num_hands=1,
                        min_detection_confidence=0.5,
                        min_tracking_confidence=0.5)

    st.markdown("<div style='text-align: center; font-size: 24px; font-weight: 600;'>ü§ö NH·∫¨N DI·ªÜN B√ÄN TAY B·∫∞NG MEDIAPIPE + ML</div>", unsafe_allow_html=True)
    st.write("S·ª≠ d·ª•ng webcam ƒë·ªÉ nh·∫≠n di·ªán c·ª≠ ch·ªâ tay theo th·ªùi gian th·ª±c.")

    run = st.checkbox('B·∫Øt ƒë·∫ßu nh·∫≠n di·ªán')
    frame_window = st.image([])

    cap = cv2.VideoCapture(0)

    while run:
        ret, frame = cap.read()
        if not ret:
            st.warning("Kh√¥ng l·∫•y ƒë∆∞·ª£c h√¨nh t·ª´ webcam!")
            break

        frame = cv2.flip(frame, 1)
        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = hands.process(rgb)

        if results.multi_hand_landmarks:
            for hand_landmarks in results.multi_hand_landmarks:
                mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)

                # Tr√≠ch xu·∫•t (x, y, z)
                landmark = []
                for lm in hand_landmarks.landmark:
                    landmark.extend([lm.x, lm.y, lm.z])

                if len(landmark) == 63:
                    probs = model.predict_proba([landmark])[0]
                    max_prob = np.max(probs)
                    predicted_label = model.classes_[np.argmax(probs)]

                    # Chuy·ªÉn nh√£n sang ti·∫øng Vi·ªát
                    predicted_label_vietnamese = label_mapping.get(predicted_label, predicted_label)

                    if max_prob > 0.7:
                        # Convert frame to Image (Pillow)
                        img_pil = Image.fromarray(frame)
                        draw = ImageDraw.Draw(img_pil)

                        # T·∫£i font h·ªó tr·ª£ ti·∫øng Vi·ªát (ch·∫≥ng h·∫°n font "Arial" ho·∫∑c b·∫°n c√≥ th·ªÉ thay b·∫±ng font kh√°c h·ªó tr·ª£ ti·∫øng Vi·ªát)
                        font = ImageFont.truetype("arial.ttf", 30)

                        # V·∫Ω text v·ªõi ti·∫øng Vi·ªát
                        draw.text((10, 50), f'C·ª≠ ch·ªâ: {predicted_label_vietnamese} ({max_prob:.2f})', font=font, fill=(0, 255, 0))

                        # Convert Image back to OpenCV format
                        frame = np.array(img_pil)

        # Hi·ªÉn th·ªã l√™n Streamlit
        frame_window.image(frame, channels="BGR")

    cap.release()
